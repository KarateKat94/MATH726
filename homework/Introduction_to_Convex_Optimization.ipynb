{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLX8EszwtfV9"
   },
   "source": [
    "# Practice with the Lagrangian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mW5epKGVtfV-"
   },
   "source": [
    "First, read Section 5.1 of [Boyd and Vandenberghe, 2004](https://web.stanford.edu/~boyd/cvxbook/) about the Lagrange dual function.  (You can omit Section 5.1.6 for now, if you like.)  As you can see from the reading, for each optimization problem of the standard form\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{minimize}&\\quad f_0(x)\\\\\n",
    "\\text{subject to}&\\quad f_i(x)\\le 0\\quad i=1,2,\\ldots,m\\\\\n",
    "&\\quad h_i(x) = 0\\quad i=1, 2, \\ldots,p\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "we define the Lagrangian\n",
    "\n",
    "$$\n",
    "L(x,\\lambda,\\nu) = f_0(x) + \\sum_{i=1}^m\\lambda_i f_i(x) + \\sum_{i=1}^p\\nu_ih_i(x).\n",
    "$$\n",
    "\n",
    "Note that $x$, $\\lambda$ and $\\nu$ are all vectors in general.  Make careful note of the direction of the inequality on $f_i(x) \\le 0$.  That's important.  Sometimes you need to do a little work to convert the problem to standard form.  Also note that the Lagrangian isn't quite unique; for example, you have some freedom in choosing what order to put the constraints in, and the constraints $h_i(x)=0$ and $-h_i(x)=0$ are equivalent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjS4rRLbtfV-"
   },
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qD6dMAnMtfV-"
   },
   "source": [
    "The Lagrangian for the problem\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{minimize}&\\quad x_1^2 - 2x_1x_2\\\\\n",
    "\\text{subject to}&\\quad 1 \\le x_1 \\le 8\\\\\n",
    "&\\quad x_1-x_2 \\ge 7\\\\\n",
    "&\\quad x_1^2 + x_2^2 = 9\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "is\n",
    "\n",
    "$$\n",
    "L(x,\\lambda,\\nu) = x_1^2 - 2x_1x_2 + \\lambda_1(1-x_1) + \\lambda_2(x_1-8) + \\lambda_3(7-x_1+x_2) + \\nu_1(x_1^2 + x_2^2 - 9). \n",
    "$$\n",
    "\n",
    "Make sure you understand why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ytmFw_otfV_"
   },
   "source": [
    "## üìù Your turn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ez7chixPtfV_"
   },
   "source": [
    "The following Markdown cell demonstrates what *typeset* answers (as opposed to coding answers) look like in a Jupyter notebook.  Notice that there is currently a placeholder that says \"YOUR ANSWER HERE\".  You need to **replace** that text with the correct answer.  In this case, you'll be using a Markdown cell.  You can (and should!) read more about Markdown formatting online.  Basically it provides a fairly simple text-based syntax for typeset text.  The Jupyter flavor of Markdown can also handle a fairly large subset of $\\LaTeX$ commands.  You can view the source of the cell you are currently reading (just double-click it) to get an idea of how this works.\n",
    "\n",
    "At this point in your careers, you should be developing good communications skills as well as creative problem-solving skills.  So, your typeset answers are expected to be clear, grammatically correct (when applicable), and nicely formatted.  If you are uncertain how to do something in the Jupyter interface, spend some time looking online for the answer.  You can also ask your instructor(s) for help, but it is good to practice finding answers from other sources as well.\n",
    "\n",
    "So, here's your first typeset question for the class: write the Lagrangian for the optimization problem\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{minimize}&\\quad x_1^2 + 3x_2\\\\\n",
    "\\text{subject to}&\\quad 2\\le x_1 \\le 12\\\\\n",
    "&\\quad x_2 \\ge 1\\\\\n",
    "&\\quad x_1 x_2 = 4\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "ryED3TCxtfV_",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "91fcde6b7a809a4bac603e9682374968",
     "grade": true,
     "grade_id": "cell-e715f50c0532c77c",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "My Answer:\n",
    "$$ L(x, \\lambda, \\nu ) = x_1^2 -2x_1x_2 + \\lambda_1(2-x_1) + \\lambda_2(x_1-12) + \\lambda_3(x_2-1) + \\nu_1(x_1x_2-4) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCv5W_extfWA"
   },
   "source": [
    "# Lagrangian duality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUzLV2WgtfWA"
   },
   "source": [
    "The next concept to understand is the Lagrange dual problem.  Every standard optimization problem (convex or not) has a natural *dual* optimization problem of the form\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{maximize}&\\quad g(\\lambda,\\nu)\\\\\n",
    "\\text{subject to}&\\quad \\lambda \\succeq 0\n",
    "\\end{align*}\n",
    "$$\n",
    "where $g$ is called the *dual objective*.\n",
    "\n",
    "Read Sections 5.1 and 5.2 of Boyd and Vandenberghe.  You may also wish to take a look at 5.3 and 5.4, which give some helpful ways of looking at duality.  The following videos fill in a few details missing from the text.\n",
    "\n",
    "<center>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <a href=\"https://youtu.be/vgw0qHyG4CY\">\n",
    "                <img src=\"https://img.youtube.com/vi/vgw0qHyG4CY/hqdefault.jpg\"><br>\n",
    "                Intro to the Lagrangian\n",
    "            </a>\n",
    "        </td>\n",
    "        <td>\n",
    "            <a href=\"https://youtu.be/ku-286oAXwc\">\n",
    "                <img src=\"https://img.youtube.com/vi/ku-286oAXwc/hqdefault.jpg\"><br>\n",
    "                Weak Duality\n",
    "            </a>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S02tu0RttfWB"
   },
   "source": [
    "# The KKT conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-igdyCbytfWB"
   },
   "source": [
    "Now you should read Section 5.5 about the KKT conditions.  Summarized in equation (5.49), the KKT conditions are a generalization of the [Lagrange multiplier theory](https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/constrained-optimization/a/lagrange-multipliers-examples) you learned in Calc III.  In particular, notice that if there are no inequality constraints, you get exactly the equations you would solve in Calc III.\n",
    "\n",
    "Solving an optimization problem using the KKT conditions is a little more complicated than what you've done before, basically because the inequality constraints complicate things somewhat.  A good technique for solving the KKT conditions is to try to guess which inequality constraints will be active.  If you assume a dual variable $\\lambda_i$ is positive, then the complimentary slackness conditions show that the associated constraint $f_i(x)\\le 0$ must be satisfied as equality.  So, for small problems, you can often make an educated guess.\n",
    "\n",
    "You might also be interested in reading Sections 5.6 and 5.7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mGSaiCyVtfWB"
   },
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qx2vWq2FtfWB"
   },
   "source": [
    "Consider, for example, the optimization problem\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\text{minimize}&\\quad (x-a)^2 + (y-b)^2\\\\\n",
    "    \\text{subject to}&\\quad 0\\le x \\le 1\\\\\n",
    "    &\\quad 0\\le y\\le 1.\n",
    "\\end{align*}\n",
    "$$\n",
    "Here $a$ and $b$ should be thought of parameters for the problem, they are not decision variables.  Now take a look at the example video below.  It shows how to derive the KKT conditions:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    0 \\le x^*,y^*\\le 1 &\\qquad\\text{primal feasibility}\\\\\n",
    "    \\lambda_1^*,\\ldots,\\lambda_4^*\\ge 0 &\\qquad\\text{dual feasibility}\\\\\n",
    "    x^* = a + \\frac{1}{2}\\left(\\lambda_1^*-\\lambda_2^*\\right) &\\qquad\\text{stationarity}\\\\\n",
    "    y^* = b + \\frac{1}{2}\\left(\\lambda_3^*-\\lambda_4^*\\right)\\\\\n",
    "    \\lambda_1^*x^* = 0,\\quad \\lambda_2^*(x^*-1)=0 &\\qquad\\text{complementary slackness}\\\\\n",
    "    \\lambda_3^*y^* = 0,\\quad \\lambda_4^*(y^*-1)=0\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "It also shows how to solve this system in two cases.  Take a look and see if you can get the hang of how the arguments work.  As a challenge, analyze the case $\\lambda_1^*,\\lambda_3^*>0$, $\\lambda_2^*=\\lambda_4^*=0$.  (As you might guess, this corresponds to the case that $a,b<0$.  See if you can prove it.)\n",
    "\n",
    "<center>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <a href=\"https://youtu.be/f1pWxXduIqk\">\n",
    "                <img src=\"https://img.youtube.com/vi/f1pWxXduIqk/hqdefault.jpg\"><br>\n",
    "                KKT Example\n",
    "            </a>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i57JR0lltfWB"
   },
   "source": [
    "## üìù Your turn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-a4p9pKtfWC"
   },
   "source": [
    "Explain why it is impossible to have both $\\lambda_1^*>0$ and $\\lambda_2^*>0$ for this example?  (Hint: look at the complementary slackness conditions.)\n",
    "If both $\\lambda_1^*$ and $\\lambda_2^*$ are positive, this means that in the case of the corresponding complementary slackness value with $\\lambda_1^*$, $x^* = 0$ and in the case of the corresponding complementary slackness value with $\\lambda_2^*$, $x^* = 1$. This is a contradiction, so it is impossible to have both $\\lambda_1^*>0$ and $\\lambda_2^*>0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UyFUKTDCtfWC"
   },
   "source": [
    "# üíª Using cvxpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gu1sri5OtfWC"
   },
   "source": [
    "One handy tool for solving small convex optimization problems is [cvxpy](http://www.cvxpy.org).  It probably won't work for super-sophisticated problems, but it's so easy to use it's a nice place to start for smaller problems.  A good way to learn about it is to solve a simple problem with it.  The examples on the website should give you a good template to base your solution on.\n",
    "\n",
    "Using cvxpy, implement the function below.  It should take two numbers, $a$ and $b$, and output the optimal point $(x^*,y^*)$ solving the problem\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\text{minimize}&\\quad (x-a)^2 + (y-b)^2\\\\\n",
    "    \\text{subject to}&\\quad x^2-1\\le y\\le x\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Notice that you've been given the skeleton of a function.  You should implement the function to have the behavior described in the docstring.  Look for the point in the code that says\n",
    "\n",
    "```\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hPT_a9jltfWC"
   },
   "source": [
    "You need to **remove** this code and replace it with the correct implementation.  The cell that follows the function is a testing cell.  Once your function is working correctly, the tests should all pass with no errors.  (Be sure to go back and re-read the text at the top of this notebook.  To ensure that your code is not using variables or functions that have inadvertently been removed from the notebook, you should always restart the kernel and run all of your code one last time before submitting it.)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1673477396166,
     "user": {
      "displayName": "Nathan Albin",
      "userId": "12921257652380671254"
     },
     "user_tz": 360
    },
    "id": "p2q1US6btfWC",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c920b37674f85467273ea5f7c0f7e3e",
     "grade": false,
     "grade_id": "cell-d85b1c0d68b0e48c",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "ExecuteTime": {
     "end_time": "2025-01-28T02:32:31.345878Z",
     "start_time": "2025-01-28T02:32:31.341753Z"
    }
   },
   "source": [
    "def solve_opt(a,b):\n",
    "    \"\"\"\n",
    "    Uses cvxpy to solve the assigned optimization problem.\n",
    "\n",
    "    Args:\n",
    "        a: The 'a' parameter.\n",
    "        b: The 'b' parameter.\n",
    "\n",
    "    Returns:\n",
    "        x,y: Tuple containing the optimal point.\n",
    "    \"\"\"\n",
    "    \n",
    "    import cvxpy as cvx\n",
    "    \n",
    "    # initialize decision variables\n",
    "    x = cvx.Variable()\n",
    "    y = cvx.Variable()\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    obj = cvx.Minimize((x-a)**2 + (y-b)**2)\n",
    "    constr = [x**2-1 <= y, y <= x]\n",
    "    prob = cvx.Problem(obj, constr)\n",
    "    prob.solve()\n",
    "    return x.value, y.value"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "executionInfo": {
     "elapsed": 908,
     "status": "ok",
     "timestamp": 1673477397067,
     "user": {
      "displayName": "Nathan Albin",
      "userId": "12921257652380671254"
     },
     "user_tz": 360
    },
    "id": "EMPBJ3qUtfWD",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da18098bea61da39dc2cd7c9d478ccac",
     "grade": true,
     "grade_id": "cell-706916f6095de258",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "6de054c1-d181-4018-e15f-d7c3ca64d57c",
    "ExecuteTime": {
     "end_time": "2025-01-28T02:32:31.927006Z",
     "start_time": "2025-01-28T02:32:31.865884Z"
    }
   },
   "source": [
    "# run some tests on the solution\n",
    "from numpy.testing import assert_almost_equal\n",
    "\n",
    "solutions = [((0.0, 0.0), (1.0646712704950963e-05, -7.265375755273091e-06)), \n",
    "             ((1.0, 0.0), (0.9999790375808776, 7.67899185353985e-06)), \n",
    "             ((0.0, 1.0), (0.49999699408512543, 0.4999969938855593)), \n",
    "             ((-2.0, -1.5), (-0.6180339879194733, -0.6180339902459888)), \n",
    "             ((2.0, 0.3), (1.2619190379423255, 0.592439656055633)), \n",
    "             ((0.8, -1.3), (0.41235233211011496, -0.8299655541699843))]\n",
    "\n",
    "for (a,b),s in solutions:\n",
    "    assert_almost_equal(s,solve_opt(a,b),decimal=4)\n",
    "    \n",
    "print('All tests passed!')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T02:57:48.342534Z",
     "start_time": "2025-01-28T02:57:48.336661Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 9
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nbgrader": {
   "__altered": false,
   "__hash": 317186325,
   "_root": {
    "entries": [
     [
      "cocalc_minimal_stubs",
      false
     ]
    ],
    "ownerID": {}
   },
   "cocalc_minimal_stubs": false,
   "size": 1
  },
  "title": "Intro to Convex Optimization"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
